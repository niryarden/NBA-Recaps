config = {
    "model_name": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "target_modules": ["q_proj", "k_proj", "v_proj",  "o_proj", "gate_proj", "up_proj", "down_proj"],
    "task_type": "CAUSAL_LM",
    "max_length": 8192,
    "max_input_length": 8192 - 1024,
    "max_output_length": 1024,
    # "max_length": 1024,
    # "max_input_length": 1024 - 512,
    # "max_output_length": 512,
    "pretrained_models_path": "/cs/snapless/roys/lab_resources",
    "finetuned_models_path": "/cs/labs/roys/nir.yarden/anlp-project/NBA-Recaps/trained_models",
    "dataset_path": "/cs/labs/roys/nir.yarden/cache",
    "processed_dataset_path": "/cs/labs/roys/nir.yarden/anlp-project/NBA-Recaps/processed_dataset",
    "dataset_name": "nir-yar/nba-pbp-to-recap",
    "lora_alpha": 32,
    "lora_r": 64,
    "lora_dropout": 0.05,
    "learning_rate": 2e-5,
    "weight_decay": 0.01,
    "batch_size": 4,
    "num_train_epochs": 3,
    "warmup_steps": 500,
    "lr_scheduler_type": "linear"
}
